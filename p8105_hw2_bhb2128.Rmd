---
title: "homework2"
author: "Brennan Baker"
date: "September 26, 2018"
output:
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Import packages.
```{r packages}
library(tidyverse)
library(readxl)
```

## Problem 1

Read and clean the data; retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. Convert the entry variable from character (YES vs NO) to a logical variable (the ifelse or recode function may be useful).

```{r import data}
subway_data <- read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry, entrance_type, vending, ada) %>% 
  mutate(entry = recode(entry, 'YES' = TRUE, 'NO' = FALSE))

```

This dataset contains NYC subway entrance and exit data. After importing the data, I cleaned the names and eliminated unnecessary variables. The resulting dataset contains the following variables: the line and station names, the longitude and latitude of each station, the routes that each station serves, whether or not each station allows entrance (entry), vending, and ADA compliance, and the type of entry. I changed the coding of the entry variable from YES/NO to TRUE/FALSE. The dataset contains `r nrow(subway_data)` rows and `r ncol(subway_data)` columns. The data set is almost tidy because the columns are variables and the rows are observations. However, the route number columns contain information about two variables, the number of the route and the name of the route.

```{r distinct stations}
distinct_stations = subway_data %>% distinct(line, station_name, .keep_all = TRUE)
```

There are `r nrow(distinct_stations)` distinct stations.

```{r ada compliant}
ada_compliant = filter(distinct_stations, ada == TRUE)
```

There are `r nrow(ada_compliant)` ADA compliant stations.

```{r no vending}
no_vending_allow_entry = subway_data %>% #move back to subway_data because each station has multiple entrances. Thus, the distinct_stations data set does not contain all of the entrances
  filter(vending == "NO") %>% 
  filter(entry == TRUE)
  
```

There are `r nrow(no_vending_allow_entry)` station entrances / exits without vending that allow entrance.

Reformat data so that route number and route name are distinct variables.
```{r tidy subway data}
tidy_subway_data = subway_data %>% 
  gather(key = route_number, value = route_name, starts_with("route")) %>% 
  separate(route_number, into = c("remove", "route_number"), sep = "e") %>% 
  select(-remove)
```

How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?
```{r a train}
a_train = tidy_subway_data %>% 
  distinct(line, station_name, .keep_all = TRUE) %>% #need distincy stations identified by name and line
  filter(route_name == "A")

ada_compliant2 = filter(a_train, ada == TRUE)
```

There are `r nrow(a_train)` distinct stations that serve the A.
There are `r nrow(ada_compliant2)` ADA compliant stations that serve the A train.

## Problem 2

```{r import trash data}
trash_data = read_excel(path = "./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = "Mr. Trash Wheel", range = cell_cols("A:M")) %>% 
  janitor::clean_names() %>% 
  mutate(sports_balls = round(sports_balls)) %>% 
  mutate(sports_balls = as.integer(sports_balls))

trash_data_2016 = trash_data %>% 
   filter(year == "2016")
```

The trash_data dataset contains data about Mr. Trash Wheel, a contraption that removes trash from the Inner Harbor in Baltimore, Maryland. The data set has `r nrow(trash_data)` rows and `r ncol(trash_data)` columns. The data set details the weight and volume of trash collected by Mr. Trash Wheel into various dumpsters each month from May 2014 through August 2017. The types of trash are sorted into several categories including plastic bottels, grocery bags, sports balls, and other trash types. The median number of sports balls per dumpster in 2016 was `r summarise(trash_data_2016, median(sports_balls))`.

```{r import and combine rain data}
rain_2016 = read_excel(path = "./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = "2016 Precipitation", range = cell_rows(2:14)) %>% 
  janitor::clean_names() %>%
  drop_na() %>% 
  mutate(year = "2016")

rain_2017 = read_excel(path = "./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = "2017 Precipitation", range = cell_rows(2:14)) %>% 
  janitor::clean_names() %>%
  drop_na() %>% 
  mutate(year = "2017")

rain_data = bind_rows(rain_2016, rain_2017) %>% 
  mutate(month = month.name[month]) %>% 
  rename(precipitation = total) %>% 
  select (year, month, precipitation)
```

The rain_data data set contains precipitation data associated with the Mr. Trash Wheel project. Presumably, this data is about monthyl precipitation rates from January 2016 through August 2017 in the Inner Harbor in Baltimore, Maryland. The data set contains `r nrow(rain_data)` rows and `r ncol(rain_data)` columns. The variables are month, year, and precipitation. Thus, each row contains the total precipitation value from each given year and month.

## Problem 3

```{r load data package}
library(p8105.datasets)
#the line below installs the package
#devtools::install_github("p8105/p8105.datasets")
```

I will tidy the data by: cleaning the names; keeping only the rows where the topic is overall health; removing state from the county column and renaming so that one column has state and another column has county; and excluding unnecessary variables. I arranged by data_value in order to investigate what range of values correspond to response (e.g. "Poor", "Very Good:).
```{r tidy data}
brfss = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  separate(locationdesc, into = c("state", "county"), sep = "- ") %>% 
  select(year, state, county, response, data_value) %>% 
  arrange(data_value)
  
```

It looks like the response variable does not depend on the data_value variable. Thus, I will choose my own values of data_value to correspond to "Poor", "Very Good", etc. 
```{r alter response variable broken}
brfss2 = brfss %>% 
  mutate(response = ifelse(data_value %in% 0.0:4.9, "Poor",
                           ifelse(data_value %in% 5.0:14.9, "Fair",
                                  ifelse(data_value %in% 15.0:29.9, "Good",
                                         ifelse(data_value %in% 30.0:39.9, "Very Good", "Excellent")))))
```

The above code turns everything in the response value column to excellent, except when data value == 1 response becomes poor. Looks like %in% does not work with decimals, which is a problem. I am going to multiply all data_values by 10

```{r alter response variable working}
brfss3 = brfss %>% mutate(data_value = data_value * 10) %>% 
  mutate(response = ifelse(data_value %in% 0:49, "Poor",
                           ifelse(data_value %in% 50:149, "Fair",
                                  ifelse(data_value %in% 150:299, "Good",
                                         ifelse(data_value %in% 300:399, "Very Good",
                                                ifelse(is.na(data_value), NA, "Excellent"))))))

```

```{r make proportions}
proportion_very_good = brfss3 %>% filter(response == "Very Good") %>% count() / brfss3 %>% count()

proportion_excellent = brfss3 %>% filter(response == "Excellent") %>% count() / brfss3 %>% count()

```

The proportion of "Very Good" responses was `r proportion_very_good` and the proportion of "Excellent" responses was `r proportion_excellent`
For this question:

format the data to use appropriate variable names;
focus on the “Overall Health” topic
exclude variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation
structure data so that responses (excellent to poor) are variables taking the value of Data_value
create a new variable showing the proportion of responses that were “Excellent” or “Very Good”
