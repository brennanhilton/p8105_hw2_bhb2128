homework2
================
Brennan Baker
September 26, 2018

-   [Problem 1](#problem-1)
-   [Problem 2](#problem-2)
-   [Problem 3](#problem-3)

Import packages.

``` r
library(tidyverse)
```

    ## -- Attaching packages ------------------------------------------------------------ tidyverse 1.2.1 --

    ## v ggplot2 3.0.0     v purrr   0.2.5
    ## v tibble  1.4.2     v dplyr   0.7.6
    ## v tidyr   0.8.1     v stringr 1.3.1
    ## v readr   1.1.1     v forcats 0.3.0

    ## -- Conflicts --------------------------------------------------------------- tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

Problem 1
---------

Read and clean the data; retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. Convert the entry variable from character (YES vs NO) to a logical variable (the ifelse or recode function may be useful).

``` r
subway_data <- read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry, entrance_type, vending, ada) %>% 
  mutate(entry = recode(entry, 'YES' = TRUE, 'NO' = FALSE))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_integer(),
    ##   Route9 = col_integer(),
    ##   Route10 = col_integer(),
    ##   Route11 = col_integer(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

This dataset contains NYC subway entrance and exit data. After importing the data, I cleaned the names and eliminated unnecessary variables. The resulting dataset contains the following variables: the line and station names, the longitude and latitude of each station, the routes that each station serves, whether or not each station allows entrance (entry), vending, and ADA compliance, and the type of entry. I changed the coding of the entry variable from YES/NO to TRUE/FALSE. The dataset contains 1868 rows and 19 columns. The data set is almost tidy because the columns are variables and the rows are observations. However, the route number columns contain information about two variables, the number of the route and the name of the route.

``` r
distinct_stations = subway_data %>% distinct(line, station_name, .keep_all = TRUE)
```

There are 465 distinct stations.

``` r
ada_compliant = filter(distinct_stations, ada == TRUE)
```

There are 84 ADA compliant stations.

``` r
no_vending_allow_entry = subway_data %>% #move back to subway_data because each station has multiple entrances. Thus, the distinct_stations data set does not contain all of the entrances
  filter(vending == "NO") %>% 
  filter(entry == TRUE)
```

There are 69 station entrances / exits without vending that allow entrance.

Reformat data so that route number and route name are distinct variables.

``` r
tidy_subway_data = subway_data %>% 
  gather(key = route_number, value = route_name, starts_with("route")) %>% 
  separate(route_number, into = c("remove", "route_number"), sep = "e") %>% 
  select(-remove)
```

How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?

``` r
a_train = tidy_subway_data %>% 
  distinct(line, station_name, .keep_all = TRUE) %>% #need distincy stations identified by name and line
  filter(route_name == "A")

ada_compliant2 = filter(a_train, ada == TRUE)
```

There are 60 distinct stations that serve the A. There are 17 ADA compliant stations that serve the A train.

Problem 2
---------

``` r
trash_data = read_excel(path = "./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = "Mr. Trash Wheel", range = cell_cols("A:M")) %>% 
  janitor::clean_names() %>% 
  mutate(sports_balls = round(sports_balls)) %>% 
  mutate(sports_balls = as.integer(sports_balls))

trash_data_2016 = trash_data %>% 
   filter(year == "2016")
```

The trash\_data dataset contains data about Mr. Trash Wheel, a contraption that removes trash from the Inner Harbor in Baltimore, Maryland. The data set has 360 rows and 13 columns. The data set details the weight and volume of trash collected by Mr. Trash Wheel into various dumpsters each month from May 2014 through August 2017. The types of trash are sorted into several categories including plastic bottels, grocery bags, sports balls, and other trash types. The median number of sports balls per dumpster in 2016 was 26.

``` r
rain_2016 = read_excel(path = "./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = "2016 Precipitation", range = cell_rows(2:14)) %>% 
  janitor::clean_names() %>%
  drop_na() %>% 
  mutate(year = "2016")

rain_2017 = read_excel(path = "./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = "2017 Precipitation", range = cell_rows(2:14)) %>% 
  janitor::clean_names() %>%
  drop_na() %>% 
  mutate(year = "2017")

rain_data = bind_rows(rain_2016, rain_2017) %>% 
  mutate(month = month.name[month]) %>% 
  rename(precipitation = total) %>% 
  select (year, month, precipitation)
```

The rain\_data data set contains precipitation data associated with the Mr. Trash Wheel project. Presumably, this data is about monthyl precipitation rates from January 2016 through August 2017 in the Inner Harbor in Baltimore, Maryland. The data set contains 20 rows and 3 columns. The variables are month, year, and precipitation. Thus, each row contains the total precipitation value from each given year and month.

Problem 3
---------

``` r
library(p8105.datasets)
#the line below installs the package
#devtools::install_github("p8105/p8105.datasets")
```

I will tidy the data by: cleaning the names; keeping only the rows where the topic is overall health; removing state from the county column and renaming so that one column has state and another column has county; and excluding unnecessary variables. I arranged by data\_value in order to investigate what range of values correspond to response (e.g. "Poor", "Very Good:).

``` r
brfss = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  separate(locationdesc, into = c("state", "county"), sep = "- ") %>% 
  select(year, state, county, response, data_value) %>% 
  arrange(data_value)
```

It looks like the response variable does not depend on the data\_value variable. Thus, I will choose my own values of data\_value to correspond to "Poor", "Very Good", etc.

``` r
brfss2 = brfss %>% 
  mutate(response = ifelse(data_value %in% 0.0:4.9, "Poor",
                           ifelse(data_value %in% 5.0:14.9, "Fair",
                                  ifelse(data_value %in% 15.0:29.9, "Good",
                                         ifelse(data_value %in% 30.0:39.9, "Very Good", "Excellent")))))
```

The above code turns everything in the response value column to excellent, except when data value == 1 response becomes poor. Looks like %in% does not work with decimals, which is a problem. I am going to multiply all data\_values by 10

``` r
brfss3 = brfss %>% mutate(data_value = data_value * 10) %>% 
  mutate(response = ifelse(data_value %in% 0:49, "Poor",
                           ifelse(data_value %in% 50:149, "Fair",
                                  ifelse(data_value %in% 150:299, "Good",
                                         ifelse(data_value %in% 300:399, "Very Good",
                                                ifelse(is.na(data_value), NA, "Excellent"))))))
```

``` r
proportion_very_good = brfss3 %>% filter(response == "Very Good") %>% count() / brfss3 %>% count()

proportion_excellent = brfss3 %>% filter(response == "Excellent") %>% count() / brfss3 %>% count()
```

The proportion of "Very Good" responses was 0.2405647 and the proportion of "Excellent" responses was 0.0196706 For this question:

format the data to use appropriate variable names; focus on the “Overall Health” topic exclude variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation structure data so that responses (excellent to poor) are variables taking the value of Data\_value create a new variable showing the proportion of responses that were “Excellent” or “Very Good”
